<html>
    <meta name="viewport" content="width=device-widh, initial-scale=1">
<head>
    <link rel="stylesheet" href="style_projects_page.css">
</head>
<body>
    <div class="dropdown">
        <button class="dropbtn">MENU</button>
        <div class="dropdown-content">
            <a href="./index.html">home page</a>
            <a href="./about.html">about</a>
            <a href="./coursework.html">coursework</a>
            <a href="./projects.html">projects</a>
            <a href="./experience.html">experience</a>
        </div>
    </div>
    <h1>CS 194-26 : Project 2 -- Fun with Filters and Frequencies</h1>
    <h1>Kunkai Lin</h1>
    <h2>Overview</h2>
    <p>The goal of the project is to apply smoothing filters (such as Gaussiann/low-pass and Laplacian/high-pass filters) and derivate filters (such as D_x, D_y)
        and play with image's frequencies to produce different kinds of interesting outputs. Specificially, the website will be divided into 2 parts: 1) The first
        part will mainly talk about the filter and 2) The second part will mainly focus on frequencies.
    </p>
    <h2>Part 1 : Fun with Filters</h2>
    <h2>Part 1.1 : Finite Difference Operator</h2>
    <p>In this part, we will first go to convolve the image of cameraman with filters in the x and y directions (D_x and D_y) to get the partial derivate in x and y.
        Then, to compute the gradient magnitude of the image, we can follow the formula introduced in lecture:
    </p>
    <h3>the gradient magnitude = sqrt((df/dx)^2 + (df/dy)^2)</h3>
    <p>and weâ€™ve already got df/dx and df/dy from previous step by convolving the image with D_x and D_y, so we just need to plug the results from the last step to this
        formula to get the gradient magnitude image. Finally, to turn the gradient magnitude image into an edge image, we binarized each pixel of the image with 
        certain threshold got by taking a few tries. The outputs are shown below:
    </p>
    <img src="./images/filter_img/cameraman_dx.jpg" width="23%" style="padding-left: 1%;">
    <img src="./images/filter_img/cameraman_dy.jpg" width="23%" style="padding-left: 1%;">
    <img src="./images/filter_img/cameraman_mag.jpg" width="23%" style="padding-left: 1%;">
    <img src="./images/filter_img/cameraman_bin.jpg" width="23%" style="padding-left: 1%;">
    <div class="end-interval"></div>
    <h2>Part 1.2 : Derivative of Gaussian (DoG) Filters</h2>
    <p>Since just the difference operator were noisy, we would go to smooth the image with Gaussian filter first before convolving it with derivative filters
        in this part. The new results are below:
    </p>
    <img src="./images/filter_img/cameraman_G_dx.jpg" width="23%" style="padding-left: 1%;">
    <img src="./images/filter_img/cameraman_G_dy.jpg" width="23%" style="padding-left: 1%;">
    <img src="./images/filter_img/cameraman_G_mag.jpg" width="23%" style="padding-left: 1%;">
    <img src="./images/filter_img/cameraman_G_bin.jpg" width="23%" style="padding-left: 1%;">
    <p>From above, the biggest difference I noticed after applying the Gaussian filter was that the edges of images became much thicker and more apparent than before.
        This is consistent with my intuition as the Gaussian filter would blur the image and smooth it by removing the noise in some extents, so the edges could be 
        emphasized when we apply derivative filters in this case.
    </p>
    <p>Since the convolution operations are associative, we can first convolve the Gaussian filter with D_x and D_y and then apply DoG filters on the original images.
        In this case, we can get the same results as above but only need to do one single convolution instead of two. Below are DoG filters as images and the results
        with DoG filters:
    </p>
    <img src="./images/filter_img/DoG_x.jpg" width="40%" style="padding-left: 5%;">
    <img src="./images/filter_img/DoG_y.jpg" width="40%" style="padding-left: 5%;">
    <img src="./images/filter_img/cameraman_DoG_dx.jpg" width="23%" style="padding-left: 1%;">
    <img src="./images/filter_img/cameraman_DoG_dy.jpg" width="23%" style="padding-left: 1%;">
    <img src="./images/filter_img/cameraman_DoG_mag.jpg" width="23%" style="padding-left: 1%;">
    <img src="./images/filter_img/cameraman_DoG_bin.jpg" width="23%" style="padding-left: 1%;">

    <div class="end-interval"></div>
    <h2>Part 2 : Fun with Frequencies</h2>
    <h2>Part 2.1 : Image "Sharpening"</h2>
    <p>To sharpen an image, we would like to add more high frequencies to the image. As Gaussian filter retains only the low frequencies, we can easily get the
        high frequencies of the image by subtracting the results from Gaussian filter from the original image. After getting the high frequencies, we simply add
        it to the original image with the coefficient alpha to get the sharpen image in different extents depends on the alpha chosen.
    </p>
    <p> Once again, due to the associativity of convolution operations, we can combine all these steps into one single convolution and this is the unsharp mask filter mentioned in lecture:</p>
    <h3>unsharp mask filter = (1 + alpha)*e - alpha*g, where e is the unit impulse; alpha is the coefficient we choose; and g is the Gaussian filter</h3>
    <h3>Note: "*" here is multiplication</h3>
    <p>The sharpen version of the sample image and two other images I choose are below (Left: Original, Right: Sharpen with alpha = 2.0):</p>
    <img src="./images/filter_img/taj.jpeg" width="15%" style="padding-left: 1%;">
    <img src="./images/filter_img/taj_sharpen.jpg" width="15%" style="padding-left: 1%;">
    <img src="./images/filter_img/dog.jpg" width="15%" style="padding-left: 1%;">
    <img src="./images/filter_img/dog_sharpen.jpg" width="15%" style="padding-left: 1%;">
    <img src="./images/filter_img/cat.jpg" width="15%" style="padding-left: 1%;">
    <img src="./images/filter_img/cat_sharpen.jpg" width="15%" style="padding-left: 1%;">
    <p>For evaluation, I also tried to blur a sharp image and then sharpen it again (Order: Original->Blur->Sharpen after blurring):</p>
    <img src="./images/filter_img/watch.jpg" width="32%" style="padding-left: 1%;">
    <img src="./images/filter_img/watch_blur.jpg" width="32%" style="padding-left: 1%;">
    <img src="./images/filter_img/watch_sharpen_after_blur.jpg" width="32%" style="padding-left: 1%;">
    <p>From above, we can notice that the original image is much sharper than the one sharpened after blurring. This is reasonable and consistent with the intuition.
        When we apply the Gaussian filter on the original image, lots of details are removed during the process, and these details play an important role on sharpening
        the image. Thus, when we tried to sharpen it again, the result is much more ambiguous than the original one.
    </p>
    <div class="end-interval"></div>
    <h2>Part 2.2 : Hybrid images</h2>
    <p>From spec, "Hybrid images are static images that change in interpretation as a function of the view distance". The basic idea of it is combining the high frequency
        part of one image and the low frequency part of another image to get a hybrid image which leads to different interpretation depends on distance. Since high frequency
        tends to dominate perception when it's available and low frequency is in opposite (dominate when there is a distance), we will see the high frequency parts when getting
        close to the image and the low frequency parts when getting far from it.
    </p>
    <p>To implement what described in the last paragraph, we should first align two images with appropriate points (such as the eyes). This can be easily done by using
        the start code given. Then, we apply Gaussian filter and Laplacian filter (unit-impulse - Gaussian filter)respectively on two images and blend the results 
        to get the hybrid image. To make the results look better, I also did the following 2 steps when applying filters on images and blending them:    
    </p>
    <h3>1.Adjust the sigma value of the Gaussian filters with some experiments to find the relatively appropriate sigma values.</h3>
    <h3>2.Tune the weights when blending the images: hybrid_image = 2 * w * high_freq + 2 * (1 - w) * low_freq, where w is in [0, 1] (Again, the "*" denotes multiplication)</h3>
    <p>Below are inputs and outputs of sample images and other images I choose (Order: Image1->Image2->Image1_aligned->Image2_aligned->Result):</p>
    <h2>Sample images:</h2>
            <img src="./images/filter_img/nutmeg.jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/DerekPicture.jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/nutmeg(aligned).jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/DerekPicture(aligned).jpg" width="18%" style="padding-left: 1%;"> 
            <img src="./images/filter_img/nutmeg+DerekPicture.jpg" width="18%" style="padding-left: 1%;">
    <h2>Images I choose:</h2>
            <img src="./images/filter_img/leopard.jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/lion.jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/leopard(aligned).jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/lion(aligned).jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/leopard+lion.jpg" width="18%" style="padding-left: 1%;">

            <img src="./images/filter_img/elepant.jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/mouse.jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/elepant(aligned).jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/mouse(aligned).jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/elepant+mouse.jpg" width="18%" style="padding-left: 1%;">

            <img src="./images/filter_img/puppy.jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/huskie.jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/puppy(aligned).jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/huskie(aligned).jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/puppy+huskie.jpg" width="18%" style="padding-left: 1%;">

            <img src="./images/filter_img/tiger.jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/car.jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/tiger(aligned).jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/car(aligned).jpg" width="18%" style="padding-left: 1%;">
            <img src="./images/filter_img/tiger+car.jpg" width="18%" style="padding-left: 1%;">

    <p>From above, we can see the most of results are good, but the last one, "tiger and car", looks weird. The failure of this group of image is mainly because of
        the bad alignment. As these two objects (tiger and car) have very distinct outline, it is very hard to find appropriate 
        points to align them. In this case, the hybrid image of them looks much worse than other groups.
    </p>
    <p>For other three pairs of images I choose, I like "leopard and lion" the most, so I illustrate the process through frequency analysis for it below:</p>
            <img src="./images/filter_img/leopard(aligned).jpg" width="23%" style="padding-left: 1%;">
            <img src="./images/filter_img/ft_im1.jpg" width="23%" style="padding-left: 1%;">
            <img src="./images/filter_img/lion(aligned).jpg" width="23%" style="padding-left: 1%;">
            <img src="./images/filter_img/ft_im2.jpg" width="23%" style="padding-left: 1%;">
            <img src="./images/filter_img/leopard_high.jpg" width="23%" style="padding-left: 1%;">
            <img src="./images/filter_img/ft_im_high.jpg" width="23%" style="padding-left: 1%;">
            <img src="./images/filter_img/lion_low.jpg" width="23%" style="padding-left: 1%;">
            <img src="./images/filter_img/ft_im_low.jpg" width="23%" style="padding-left: 1%;">
            <img src="./images/filter_img/leopard+lion.jpg" width="23%" style="padding-left: 1%;">
            <img src="./images/filter_img/ft_im_hybrid.jpg" width="23%" style="padding-left: 1%;">
    <div class="end-interval"></div>
    <h2>Part 2.3 : Gaussian and Laplacian Stacks</h2>
    <p>For this part, I am going to implement Gaussian and Laplacian stacks for the multi-resolution blending in next part. Gaussian stack is just the Gaussian
        pyramid without downsampling. To get the Laplacian image for each level, we just need to subtract the Gaussian image at that level from the one at the 
        last level (i.e. Laplacian stack level 1 = Gaussian stack level 1 - Gaussian stack level 0). In addition, different from the Gaussian pyramid,
        I use the same Gaussian filter in an auto-regressive fashion (after asking TA on piazza) instead of double the filter's kernel size each level.
    </p>
    <p>Below are the results got by applying my stack function to Oraple and recreate the outcomes in textbook (Order: from lower to higher level):</p>
            <img src="./images/filter_img/applemasked0.jpg" width="14%">
            <img src="./images/filter_img/applemasked1.jpg" width="14%">
            <img src="./images/filter_img/applemasked2.jpg" width="14%">
            <img src="./images/filter_img/applemasked3.jpg" width="14%">
            <img src="./images/filter_img/applemasked4.jpg" width="14%">
            <img src="./images/filter_img/applemasked5.jpg" width="14%">
            <img src="./images/filter_img/applemasked.jpg" width="14%">

            <img src="./images/filter_img/orangemasked0.jpg" width="14%">
            <img src="./images/filter_img/orangemasked1.jpg" width="14%">
            <img src="./images/filter_img/orangemasked2.jpg" width="14%">
            <img src="./images/filter_img/orangemasked3.jpg" width="14%">
            <img src="./images/filter_img/orangemasked4.jpg" width="14%">
            <img src="./images/filter_img/orangemasked5.jpg" width="14%">
            <img src="./images/filter_img/orangemasked.jpg" width="14%">

            <img src="./images/filter_img/oraple0.jpg" width="14%">
            <img src="./images/filter_img/oraple1.jpg" width="14%">
            <img src="./images/filter_img/oraple2.jpg" width="14%">
            <img src="./images/filter_img/oraple3.jpg" width="14%">
            <img src="./images/filter_img/oraple4.jpg" width="14%">
            <img src="./images/filter_img/oraple5.jpg" width="14%">
            <img src="./images/filter_img/oraple.jpg" width="14%">
                             
    <div class="end-interval"></div>
    <h2>Part 2.4 : multi-resolution Blending</h2>
    <p>This is the final part for this project. In this part, I'm going to blend a couple of images by "pyramid" blending with the help from the stack function I build in
        part 2.3. I use "pyramid" instead of pyramid since I actually use stack here. As described in lecture, the general approach looks like this:
    </p>
    <h3>1.Build Laplacian stacks LA LB from image A and B</h3>
    <h3>2.Build Gaussian stack GR from selected region R</h3>
    <h3>3.Form a combined stack LS from LA LB using nodes of GR as weights: LS = GR * LA + (1 - GR) * LB</h3>
    <h3>4.Collapse LS to get the final result</h3>
    <p>The first step can be easily done by using the stack function defined in part 2.3. The third and forth step can also be completed by plugging the corresponding images to the formula,
        and the only thing needed to be noticed here is that we should collapse LS starting from the last images in Gaussian stacks of two input images (I forgot this on my first attempt and this affected a lot).
        However, for the second step, we need to first construct a binary mask having pixels with value = 0 or 1 depends on how we would like to blend the images. For the
        oraple, it is naive and we just need to use a mask having a vertical seam in the middle. But for some other images below, we have to build irregular masks. In this 
        case, I construct the masks by iteratively checking the pixel values and seting a threshold depends on input image + some hardcode. For example, if one input image's
        backgroud-color is all white (i.e. having the pixel values of 1) and the region we would like to blend is the only part which is not white (i.e. having pixel values
        samller than 1), I will then traverse through that image and find all indexes having pixel values smaller than 0.95 and set the corresponding indexes in the mask to 1.
    </p>
    <p>Below are the results from sample images and images I choose (including two inputs + mask/the region selected + blending result) :</p>
    <h2>Images I choose:</h2>
    <p>(for the iris image, I first add paddings to it to make it the same size as blackhole image)</p>
            <img src="./images/filter_img/iris.jpg" width="23%" style="padding-left: 1%">
            <img src="./images/filter_img/blackhole.jpg" width="23%" style="padding-left: 1%">
            <img src="./images/filter_img/blackirismask.jpg" width="23%" style="padding-left: 1%">
            <img src="./images/filter_img/blackiris.jpg" width="23%" style="padding-left: 1%">

            <img src="./images/filter_img/littlecat.jpg" width="23%" style="padding-left: 1%">
            <img src="./images/filter_img/spiderman.jpg" width="23%" style="padding-left: 1%">
            <img src="./images/filter_img/spidercatmask.jpg" width="23%" style="padding-left: 1%">
            <img src="./images/filter_img/spidercat.jpg" width="23%" style="padding-left: 1%">

            <img src="./images/filter_img/ironman.jpg" width="23%" style="padding-left: 1%">
            <img src="./images/filter_img/tony.jpg" width="23%" style="padding-left: 1%">
            <img src="./images/filter_img/irontonymask.jpg" width="23%" style="padding-left: 1%">
            <img src="./images/filter_img/irontony.jpg" width="23%" style="padding-left: 1%">

    <div class="end-interval"></div>
    <h2>Bells & Whistles:</h2>
    <p>For Bells & Whistles, I added color to part 2.4 and got the colored blending. To add color to the results, I just split the colored input images at the beginning, and took each
        of the channels as a single image and blended them respectively using the same techinque when dealing with the gray-scale image above. Then, after completing the blending of all 3 channels, 
        I combined them together at the end to get the colored results. From the results, I felt the adding color definitely enhanced the effect a lot.
    </p>
    <p>Below are the colored results for each blending in part 2.4:</p>
            <img src="./images/filter_img/oraple_color.jpg" width="23%" style="padding-left: 1%">
            <img src="./images/filter_img/blackiris_color.jpg" width="23%" style="padding-left: 1%">
            <img src="./images/filter_img/spidercat_color.jpg" width="23%" style="padding-left: 1%">
            <img src="./images/filter_img/irontony_color.jpg" width="23%" style="padding-left: 1%">
    <div class="end-interval"></div>
    <h2>Conclusion:</h2>
    <p>In overall, I learned a lot and had a lof of fun by doing this project. The most interesting thing I learned from it should be the hybrid image and
        the multi-resolution blending. It's amazing that a static image can have completely different views depends on the distance. Through this, I understood
        the frequencies much better. For the multi-resolution blending part, I blended the little cat and spiderman to get a "spidercat" which was very funny I thought.
        Also, the blending of "blackiris" and "irontony" were pretty cool, too. 
    </p>
    <div class="end"></div>
    <a href="./projects.html"><h3>BACK</h3></a>

    <div class="end-interval"></div>
</body>

</html>